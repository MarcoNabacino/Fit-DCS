{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Introduction\n",
    "\n",
    "`Fit-DCS` is a Python toolbox for modeling and analyzing diffuse correlation spectroscopy (DCS) data. It provides tools for both forward modeling\n",
    "and inverse fitting of DCS autocorrelation functions, allowing users to extract information about scatterer dynamics in turbid media.\n",
    "\n",
    "This Jupyter Notebook provides an introduction to the main features of the `Fit-DCS` toolbox, complete with code examples and exercises to familiarize\n",
    "users with its capabilities.\n",
    "\n",
    "# Forward modeling\n",
    "\n",
    "The simplest use of this toolbox is the modeling of the forward problem, that is, given the information on the scatterer dynamics\n",
    "(Brownian diffusion coefficient `db` and/or mean square velocity `v_ms` depending on the scatterer model) and the geometry (e.g., semi-infinite,\n",
    "slab, ...) calculate the corresponding autocorrelation functions `g1` and `g2`.\n",
    "\n",
    "The `forward` module contains the expressions for the normalized and unnormalized first-order autocorrelations `g1_norm` and `g1`\n",
    "obtained in the framework of the diffusion approximation to the correlation transport equation.\n",
    "It contains one submodule per geometry: for example, `forward.homogeneous_inf` contains the solution for the homogeneous\n",
    "semi-infinite geometry, `forward.homogeneous_slab` the ones for the homogeneous laterally infinite slab, and so on.\n",
    "\n",
    "In addition to a geometric model, we also need a model for scatterer motion. These can be found in `forward.common`, and include\n",
    "Brownian motion, ballistic motion and hybrid motion with both components.\n",
    "\n",
    "## Semi-infinite geometry\n",
    "\n",
    "We'll start with a simple example of forward modeling in a semi-infinite geometry with Brownian motion.\n",
    "First of all, let's import the necessary modules and define the parameters of the simulation."
   ],
   "id": "df8cfbe5d6d922d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np                                          # Arrays\n",
    "import matplotlib.pyplot as plt                             # Plotting\n",
    "from matplotlib.lines import lineStyles\n",
    "\n",
    "from fit_dcs.forward import common                          # Common functions (e.g., scatterer motion models)\n",
    "from fit_dcs.forward import homogeneous_semi_inf as hsi     # Semi-infinite geometry\n",
    "\n",
    "tau = np.logspace(-8, 0, 200)               # Delay times, s\n",
    "lambda0 = 785                               # Wavelength, nm\n",
    "mua = 0.1                                   # Absorption coefficient, 1/cm\n",
    "musp = 10                                   # Reduced scattering coefficient, 1/cm\n",
    "rho = 2.5                                   # Source-detector separation, cm\n",
    "n = 1.4                                     # Refractive index of the medium (external is 1)\n",
    "db = 1e-8                                   # Brownian diffusion coefficient, cm^2/s\n",
    "beta = 0.5                                  # Coherence of detected light"
   ],
   "id": "bc74f0dfd1061fd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Note that, in order to be flexible, the geometric models in `Fit-DCS` do not take directly the Brownian diffusion coefficient `db` as input,\n",
    "but rather the mean-square displacement (MSD) as a function of delay time `tau`.\n",
    "This allows the user to define custom scatterer motion models if needed.\n",
    "\n",
    "For simple Brownian motion, we can use the helper function `msd_brownian` in the `common` module to compute the MSD."
   ],
   "id": "7868baeb4e7546f5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "msd = common.msd_brownian(tau, db)\n",
    "g1_norm = hsi.g1_norm(msd, mua, musp, rho, n, lambda0)"
   ],
   "id": "72ce433ada6df7ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "We can now compute the second-order autocorrelation function `g2` using the Siegert relation and plot the results.",
   "id": "752767e6d01a6aff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "g2_norm = 1 + beta * g1_norm**2\n",
    "\n",
    "def plot_g1_g2(tau, g1, g2, labels=None):\n",
    "    \"\"\"\n",
    "    Helper function to plot g1 and g2. Supports multiple curves with labels.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(2, 1, sharex=True)\n",
    "    axs[0].semilogx(tau, g1.T, label=labels)\n",
    "    axs[0].set_xlabel(r'$\\tau$ (s)')\n",
    "    axs[0].set_ylabel(r'$g_1$')\n",
    "    if labels is not None:\n",
    "        axs[0].legend()\n",
    "\n",
    "    axs[1].semilogx(tau, g2.T, label=labels)\n",
    "    axs[1].set_xlabel(r'$\\tau$ (s)')\n",
    "    axs[1].set_ylabel(r'$g_2$')\n",
    "    if labels is not None:\n",
    "        axs[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_g1_g2(tau, g1_norm, g2_norm)"
   ],
   "id": "55cda736e45772b4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Let's now try different values of the Brownian diffusion coefficient `db` and see how they affect the autocorrelation functions.\n",
    "We will define `g1` as a 2D array whose axes are `(db, tau)`, and loop over different `db` values to compute `g1` for each.\n",
    "This 2D structure for `g1` and `g2` is what is expected by data analysis classes, where the first axis corresponds to\n",
    "different iterations and the second axis to delay times."
   ],
   "id": "7c590817744273f0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_vals = [1e-9, 2e-9, 5e-9, 1e-8, 2e-8]\n",
    "g1_all = np.zeros((len(db_vals), len(tau)))\n",
    "for i, db in enumerate(db_vals):\n",
    "    msd = common.msd_brownian(tau, db)\n",
    "    g1_all[i, :] = hsi.g1_norm(msd, mua, musp, rho, n, lambda0)\n",
    "g2_all = 1 + beta * g1_all**2\n",
    "\n",
    "plot_g1_g2(tau, g1_all, g2_all, labels=db_vals)  # We can pass the db values to be used in the legend"
   ],
   "id": "28d42b0e52250942",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now try writing some code to simulate `g1` and `g2` for the same geometry but with ballistic scatterer motion.\n",
    "Use the function `common.msd_ballistic` to compute the mean-square displacement for ballistic motion.\n",
    "Hover over the function name to see its documentation, including the input parameters."
   ],
   "id": "962b60ce6c7fb677"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "v_ms_vals = []  # Your code here... (mean square velocities, (cm/s)^2)\n",
    "g1_all = np.zeros((len(v_ms_vals), len(tau)))\n",
    "g2_all = np.zeros((len(v_ms_vals), len(tau)))\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "plot_g1_g2(tau, g1_all, g2_all, labels=v_ms_vals)"
   ],
   "id": "ea83cb7088577559",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, also try simulating `g1` and `g2` for a hybrid motion model with both Brownian and ballistic components.\n",
    "You can use the function `common.msd_hybrid` to compute the mean-square displacement for hybrid motion."
   ],
   "id": "62d3e2a65e06de13"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_vals = []  # Your code here...\n",
    "v_ms = 1e-4\n",
    "g1_all = np.zeros((len(db_vals), len(tau)))\n",
    "g2_all = np.zeros((len(db_vals), len(tau)))\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "plot_g1_g2(tau, g1_all, g2_all, labels=db_vals)"
   ],
   "id": "9d87d41e837f0ae6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Slab geometry\n",
    "\n",
    "The procedure for forward modeling in a slab geometry is similar to the semi-infinite case.\n",
    "We just need to import the appropriate module (`forward.homogeneous_inf_slab`) and define the additional\n",
    "parameters for the slab geometry.\n",
    "Since the theoretical model requires a sum over multiple image sources, we also need to define the number\n",
    "of image sources to include in the calculation (`m_max`).\n",
    "\n",
    "Note that two solutions are available for the slab geometry, one in reflectance (`g1_reflectance_norm`)\n",
    "and one in transmittance (`g1_transmittance_norm`).\n",
    "\n",
    "Let's see an example."
   ],
   "id": "820313343cc667c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fit_dcs.forward import homogeneous_inf_slab as slab\n",
    "\n",
    "d = 0.5                                   # Slab thickness, cm\n",
    "m_max = 10                                # Number of image sources to include\n",
    "rho = 2.5                                 # Lateral source-detector separation, cm\n",
    "db = 1e-8\n",
    "\n",
    "msd = common.msd_brownian(tau, db)\n",
    "g1_norm = slab.g1_reflectance_norm(msd, mua, musp, rho, n, lambda0, d, m_max)\n",
    "\n",
    "g2_norm = 1 + beta * g1_norm**2\n",
    "plot_g1_g2(tau, g1_norm, g2_norm)"
   ],
   "id": "a1ec175f51a5e5eb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "Now try to verify that the slab solution in reflectance is the same as the semi-infinite solution\n",
    "when we only consider the first image source (i.e., set `m_max = 0`)."
   ],
   "id": "49c10e18364f2178"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "g1_semi_inf = np.zeros_like(tau)\n",
    "g1_slab_m0 = np.zeros_like(tau)\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "# Plotting\n",
    "plt.semilogx(tau, g1_semi_inf, label='Semi-infinite')\n",
    "plt.semilogx(tau, g1_slab_m0, '--', label='Slab m=0')\n",
    "plt.xlabel(r'$\\tau$ (s)')\n",
    "plt.ylabel(r'$g_1$')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "f094d7f6f783bf66",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, let's study the convergence of the slab solution as we increase the number of image sources `m_max`.\n",
    "Try simulating `g1` and `g2` in the transmittance geometry for different values of `m_max`."
   ],
   "id": "33f8603e233f3b5c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mua = 0.05\n",
    "musp = 10\n",
    "d = 0.5\n",
    "rho = 2  # Lateral source-detector separation, it's usually 0 in transmittance\n",
    "db = 1e-8\n",
    "msd = common.msd_brownian(tau, db)\n",
    "m_max_vals = []  # Your code here...\n",
    "\n",
    "g1_all = np.zeros((len(m_max_vals), len(tau)))\n",
    "g2_all = np.zeros((len(m_max_vals), len(tau)))\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "plot_g1_g2(tau, g1_all, g2_all, labels=m_max_vals)"
   ],
   "id": "ec6b0c35276d7f22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "The parameters defined above were chosen to highlight the effect of increasing `m_max`. Try changing them\n",
    "to see how they affect the convergence behavior. You should observe that higher absorption coefficients, thicker slabs,\n",
    "and shorter source-detector separations require fewer image sources for convergence."
   ],
   "id": "738174751c0f0d89"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Two-layer geometry\n",
    "\n",
    "Finally, let's simulate the autocorrelation for a two-layer geometry.\n",
    "The appropriate `g1_norm` function can be found in the `forward.bilayer` module.\n",
    "\n",
    "The main difference with respect to the previous cases is that now we are dealing with two different media,\n",
    "each with its scatterer motion. As such, in `forward.bilayer.g1_norm`, the `msd` argument is a 2D array of shape\n",
    "`(2, len(tau))`, such that `msd[0, :]` is the mean-square displacement for the upper layer's scatterers and\n",
    "`msd[1, :]` is the one relative to the lower layer. Of course, the scatterer motion models can be different in the two layers.\n",
    "\n",
    "Additionally, the analytical expression contains an integration over all (positive) spatial frequencies, which in the\n",
    "implementation is truncated to the interval `(0, q_max)`, where `q_max` is an input parameter.\n",
    "\n",
    "Let's see an example. For simplicity, we'll consider Brownian motion in both layers."
   ],
   "id": "3f1b15ba33049ec0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import fit_dcs.forward.bilayer as bilayer\n",
    "\n",
    "db_up = 1e-8\n",
    "db_dn = 6e-8\n",
    "msd_up = common.msd_brownian(tau, db_up)\n",
    "msd_dn = common.msd_brownian(tau, db_dn)\n",
    "msd = np.vstack((msd_up, msd_dn))  # Shape (2, len(tau))\n",
    "mua_up = 0.1\n",
    "mua_dn = 0.2\n",
    "musp_up = 8\n",
    "musp_dn = 10\n",
    "n = 1.4\n",
    "d = 1  # Thickness of the upper layer, cm\n",
    "rho = 3\n",
    "q_max = 80  # 1/cm\n",
    "\n",
    "g1_norm = bilayer.g1_norm(msd, mua_up, mua_dn, musp_up, musp_dn, n, d, rho, lambda0, q_max)\n",
    "g2_norm = 1 + beta * g1_norm**2\n",
    "\n",
    "plot_g1_g2(tau, g1_norm, g2_norm)"
   ],
   "id": "5622ea0aaecbc1c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "To study the convergence of the solution, try simulating `g1` and `g2` for different values of `q_max`.",
   "id": "36c53b2b51cb2019"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "q_max_vals = []  # Your code here...\n",
    "g1_all = np.zeros((len(q_max_vals), len(tau)))\n",
    "g2_all = np.zeros((len(q_max_vals), len(tau)))\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "plot_g1_g2(tau, g1_all, g2_all, labels=q_max_vals)"
   ],
   "id": "81f6eb0d5c9b3b03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now try investigating the effect of the lower layer's Brownian diffusion coefficient `db_dn` on the autocorrelation functions.\n",
    "You should use a value of `q_max` that ensures convergence, which you can determine from the previous exercise."
   ],
   "id": "dd8eea70f3ec676d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_dn_vals = []  # Your code here...\n",
    "g1_all = np.zeros((len(db_dn_vals), len(tau)))\n",
    "g2_all = np.zeros((len(db_dn_vals), len(tau)))\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "plot_g1_g2(tau, g1_all, g2_all, labels=db_dn_vals)"
   ],
   "id": "efaf80452753ca6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Finally, repeat the previous exercise with a different source-detector separation `rho`.\n",
    "You should observe that the sensitivity to the lower layer's dynamics increases with `rho`.\n",
    "\n",
    "You are also free to change other parameters (e.g., upper layer thickness `d`, scatterer motion model, ...) to see how they affect the results."
   ],
   "id": "4038cd5ec980605e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Adding noise\n",
    "\n",
    "So far all the curves we generated were noiseless, as they were obtained using the analytical solutions to the correlation diffusion equation.\n",
    "In this section, we will see how to add realistic noise to the simulated `g2` curves.\n",
    "\n",
    "The `utils.noise` module offers noise-related functionalities, most importantly the expression for the standard deviation of `g2_norm` as a\n",
    "function of time delay `tau`.\n",
    "This model was obtained for an exponentially decaying `g2_norm`, that is, `g2_norm = 1 + beta * exp(-tau/tau_c)`, which works best at short\n",
    "time delays.\n",
    "\n",
    "Let's plot the standard deviation. To get more realistic results, we will load the `tau` which comes from a hardware correlator,\n",
    "rather than creating it ourselves as we did earlier. Additionally, the standard deviation depends on integration time, measurement countrate,\n",
    "decay time constant, and number of detected speckles, so we will need to define those as well."
   ],
   "id": "5ac232c8c610de77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fit_dcs.utils import noise\n",
    "\n",
    "tau = np.load(\"data/tau.npz\")[\"tau_hardware\"]\n",
    "\n",
    "t_integration = 1   # Integration time, s\n",
    "countrate = 70_000  # Measurement countrate, Hz\n",
    "tau_c = 1e-5        # Exponential decay time constant, s\n",
    "n_speckle = 1       # Number of speckles detected in parallel\n",
    "sigma = noise.sigma_g2_norm(tau, t_integration, countrate, beta, tau_c, n_speckle)\n",
    "\n",
    "# Plotting\n",
    "plt.semilogx(tau, sigma)\n",
    "plt.xlabel(r\"$\\tau$ (s)\")\n",
    "plt.ylabel(r\"$\\sigma$\")\n",
    "plt.title(r\"Standard deviation of $g_2 (\\tau)$\")\n",
    "plt.show()"
   ],
   "id": "f2a17ed5cd73ba86",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We notice two features about this plot:\n",
    "1. First, the step-like behavior, which stems from the stepped bin width used in the correlator.\n",
    "2. Second, the non-decreasing trend: while the noise initially decreases with `tau`, it later increases again starting from about 1 ms.\n",
    "This behavior is inconsistent with experimental observations, which show a decreasing trend over the whole time delay range.\n",
    "This failure of the noise model at high delays has been previously observed in the scientific literature.\n",
    "\n",
    "Depending on our application, we might want to modify the output of this function, for example by manually setting `sigma`\n",
    "at the late bins to its minimum value to ensure a decreasing trend:"
   ],
   "id": "af70810c22ddf22e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "idx_last_good = np.argmin(sigma)\n",
    "sigma_corrected = sigma.copy()\n",
    "sigma_corrected[idx_last_good + 1:] = sigma_corrected[idx_last_good]\n",
    "plt.semilogx(tau, sigma, label=\"Original\")\n",
    "plt.semilogx(tau, sigma_corrected, linestyle=\"\", marker=\".\", label=\"Corrected\")\n",
    "plt.xlabel(r\"$\\tau$ (s)\")\n",
    "plt.ylabel(r\"$\\sigma$\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "12a4c8b1d27e992f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now that we have the noise model, we can use it to add noise to our autocorrelation curves to mimic a real measurement. To do this,\n",
    "once we have calculated the noiseless `g2_norm`, we will sample from a Gaussian distribution with mean `g2_norm` and standard deviation\n",
    "`sigma`.\n",
    "\n",
    "Remember that the `sigma_g2_norm` function takes as input `tau_c`, the time constant of the exponential decay. To estimate this, the\n",
    "`g2_norm` curve should be fitted with the exponential function defined above.\n",
    "\n",
    "The `noise` module provides a `NoiseAdder` class that automates this process. The constructor take as input the integration time,\n",
    "countrate, beta, and number of speckles, while the `add_noise` method takes `tau` and `g2_norm` as inputs and returns the noisy\n",
    "`g2_norm_noisy`.\n",
    "\n",
    "Let's see an example. For simplicity's sake, we'll use the semi-infinite geometry with Brownian motion again, but the noise addition\n",
    "can be applied to any `g2_norm` curve."
   ],
   "id": "c29679b5ea1dc611"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mua = 0.1\n",
    "musp = 10\n",
    "rho = 2.5\n",
    "n = 1.4\n",
    "db = 1e-8\n",
    "beta = 0.5\n",
    "\n",
    "msd = common.msd_brownian(tau, db)\n",
    "g1_norm = hsi.g1_norm(msd, mua, musp, rho, n, lambda0)\n",
    "g2_norm = 1 + beta * g1_norm**2\n",
    "\n",
    "t_integration = 1   # Integration time, s\n",
    "countrate = 70_000  # Measurement countrate, Hz\n",
    "n_speckle = 1       # Number of speckles detected in parallel\n",
    "\n",
    "noise_adder = noise.NoiseAdder(t_integration, countrate, beta, n_speckle)\n",
    "g2_norm_noisy = noise_adder.add_noise(tau, g2_norm)\n",
    "\n",
    "# Plotting\n",
    "plt.semilogx(tau, g2_norm, label='Noiseless')\n",
    "plt.semilogx(tau, g2_norm_noisy, marker='.', linestyle='', label='Noisy')\n",
    "plt.xlabel(r'$\\tau$ (s)')\n",
    "plt.ylabel(r'$g_2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "f5a1c6ce5e1b7d05",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Notice how the noise decreases with increasing `tau`, as expected. However, for large `tau`, it increases again due to\n",
    "the limitations of the noise model discussed earlier. To mitigate this, the `NoiseAdder` class constructor also accepts\n",
    "an optional boolean argument `ensure_decreasing` (default `False`): when set to `True`, it applies the correction we saw earlier\n",
    "to ensure a decreasing noise trend."
   ],
   "id": "991185cc89ad6eed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise_adder = noise.NoiseAdder(t_integration, countrate, beta, n_speckle, ensure_decreasing=True)\n",
    "g2_norm_noisy = noise_adder.add_noise(tau, g2_norm)\n",
    "\n",
    "# Plotting\n",
    "plt.semilogx(tau, g2_norm, label='Noiseless')\n",
    "plt.semilogx(tau, g2_norm_noisy, marker='.', linestyle='', label='Noisy')\n",
    "plt.xlabel(r'$\\tau$ (s)')\n",
    "plt.ylabel(r'$g_2$')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "a7197908e374fdb2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can see, now the noise decreases with increasing `tau`, which is more realistic.\n",
    "\n",
    "Now try simulating several noisy `g2_norm` curves for different Brownian diffusion coefficients `db`.\n",
    "Start by creating the noiseless `g2_norm` curves, then use the `NoiseAdder` class to add noise to each of them."
   ],
   "id": "efb6eae4dfa97037"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "db_vals = []  # Your code here...\n",
    "\n",
    "t_integration = 1\n",
    "countrate = 70_000\n",
    "n_speckle = 1\n",
    "\n",
    "g1_all = np.zeros((len(db_vals), len(tau)))\n",
    "g2_all = np.zeros((len(db_vals), len(tau)))\n",
    "g2_all_noisy = np.zeros((len(db_vals), len(tau)))\n",
    "\n",
    "# Your code here...\n",
    "\n",
    "# Plotting\n",
    "for i in range(len(db_vals)):\n",
    "    plt.semilogx(tau, g2_all[i, :], alpha=0.3, color=f\"C{i}\")\n",
    "    plt.semilogx(tau, g2_all_noisy[i, :], '.', color=f\"C{i}\")\n",
    "plt.xlabel(r'$\\tau$ (s)')\n",
    "plt.ylabel(r'$g_2$')\n",
    "plt.show()"
   ],
   "id": "e104f69577656d06",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Finally, try changing the noise parameters (integration time, countrate, number of speckles) to see how they affect the noisy curves.",
   "id": "9f6a184cb5deb74d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Analyzing DCS data\n",
    "\n",
    "In addition to forward modeling, the `Fit-DCS` toolbox also provides tools for solving the inverse problem, that is,\n",
    "extracting scatterer dynamics from measured autocorrelation functions. These are implemented in the `inverse` module, which\n",
    "comprises two submodules: `fit` and `mbl_homogeneous`.\n",
    "\n",
    "We will start with the `fit` submodule, which contains the general-purpose `Fitter` class for fitting DCS autocorrelation data using\n",
    "arbitrary forward models.\n",
    "\n",
    "Let's start by creating some synthetic data to fit. We'll start by simulating `db` changes over time to mimic an occlusion experiment."
   ],
   "id": "2207bda6a75f8d5b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "baseline_value = 5e-9\n",
    "baseline_length = 20\n",
    "occlusion_value = 3e-10\n",
    "occlusion_length = 20\n",
    "peak_value = 6 * baseline_value\n",
    "rising_time = 5\n",
    "falling_time = 20\n",
    "total_dur = baseline_length + occlusion_length + rising_time + falling_time\n",
    "db = np.zeros(total_dur)\n",
    "db[:baseline_length] = baseline_value\n",
    "db[baseline_length:baseline_length + occlusion_length] = occlusion_value\n",
    "db[baseline_length + occlusion_length:baseline_length + occlusion_length + rising_time] = np.linspace(occlusion_value, peak_value, rising_time)\n",
    "db[baseline_length + occlusion_length + rising_time:baseline_length + occlusion_length + rising_time + falling_time] = np.linspace(peak_value, baseline_value, falling_time)\n",
    "\n",
    "plt.plot(db)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(r\"$D_B$ (cm$^2$/s)\")\n",
    "plt.show()"
   ],
   "id": "9a4c1343ec801e55",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Now use the semi-infinite forward model to simulate `g2_norm` curves for each `db` value, and add noise to them using the `NoiseAdder` class.\n",
    "Remember that `g2_norm` should be a 2D array with shape `(total_dur, len(tau))`."
   ],
   "id": "c551bcd475f382a0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mua = 0.1\n",
    "musp = 10\n",
    "rho = 2.5\n",
    "\n",
    "g1_all = np.zeros((total_dur, len(tau)))\n",
    "g2_all = np.zeros((total_dur, len(tau)))\n",
    "g2_all_noisy = np.zeros((total_dur, len(tau)))\n",
    "\n",
    "# Create noiseless g2_all\n",
    "# Your code here...\n",
    "\n",
    "# Create noisy g2_all_noisy\n",
    "t_integration = 1\n",
    "countrate = 70_000\n",
    "n_speckle = 4\n",
    "# Your code here...\n",
    "\n",
    "# Plotting a few curves\n",
    "for i in range(0, total_dur, 10):\n",
    "    plt.semilogx(tau, g2_all[i, :], color=f\"C{i//10}\", label=i)\n",
    "    plt.semilogx(tau, g2_all_noisy[i, :], '.', color=f\"C{i//10}\")\n",
    "plt.xlabel(r'$\\tau$ (s)')\n",
    "plt.ylabel(r'$g_2$')\n",
    "plt.legend(title=\"Iteration\")\n",
    "plt.show()"
   ],
   "id": "1d48e01f969f3ae3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
